{
  "cluster_id": 15,
  "papers": [
    {
      "id": "cvpr25_695",
      "paper_id": "",
      "title": "3D Prior Is All You Need: Cross-Task Few-shot 2D Gaze Estimation",
      "authors": "Yihua Cheng, Hengfei Wang, Zhongqun Zhang, Yang Yue, Boeun Kim, Feng Lu, Hyung Jin Chang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_3D_Prior_Is_All_You_Need_Cross-Task_Few-shot_2D_Gaze_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_68",
      "paper_id": "",
      "title": "A Light Weight Model for Active Speaker Detection",
      "authors": "Junhua Liao, Haihan Duan, Kanghui Feng, Wanbing Zhao, Yanbing Yang, Liangyin Chen",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liao_A_Light_Weight_Model_for_Active_Speaker_Detection_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_1428",
      "paper_id": "",
      "title": "A Proposal-Based Paradigm for Self-Supervised Sound Source Localization in Videos",
      "authors": "Hanyu Xuan, Zhiliang Wu, Jian Yang, Yan Yan, Xavier Alameda-Pineda",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Xuan_A_Proposal-Based_Paradigm_for_Self-Supervised_Sound_Source_Localization_in_Videos_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr22_298",
      "paper_id": "",
      "title": "A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation",
      "authors": "Yutong Chen, Fangyun Wei, Xiao Sun, Zhirong Wu, Stephen Lin",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_A_Simple_Multi-Modality_Transfer_Learning_Baseline_for_Sign_Language_Translation_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_1354",
      "paper_id": "",
      "title": "A Study of Dropout-Induced Modality Bias on Robustness to Missing Video Frames for Audio-Visual Speech Recognition",
      "authors": "Yusheng Dai, Hang Chen, Jun Du, Ruoyu Wang, Shihao Chen, Haotian Wang, Chin-Hui Lee",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Dai_A_Study_of_Dropout-Induced_Modality_Bias_on_Robustness_to_Missing_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_1733",
      "paper_id": "",
      "title": "Adapting to the Unknown: Training-Free Audio-Visual Event Perception with Dynamic Thresholds",
      "authors": "Eitan Shaar, Ariel Shaulov, Gal Chechik, Lior Wolf",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Shaar_Adapting_to_the_Unknown_Training-Free_Audio-Visual_Event_Perception_with_Dynamic_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_359",
      "paper_id": "",
      "title": "Animate and Sound an Image",
      "authors": "Xihua Wang, Ruihua Song, Chongxuan Li, Xin Cheng, Boyuan Li, Yihan Wu, Yuyue Wang, Hongteng Xu, Yunfeng Wang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Animate_and_Sound_an_Image_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_2119",
      "paper_id": "",
      "title": "Audio-Visual Grouping Network for Sound Localization From Mixtures",
      "authors": "Shentong Mo, Yapeng Tian",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Mo_Audio-Visual_Grouping_Network_for_Sound_Localization_From_Mixtures_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr21_534",
      "paper_id": "",
      "title": "Audio-Visual Instance Discrimination with Cross-Modal Agreement",
      "authors": "Pedro Morgado, Nuno Vasconcelos, Ishan Misra",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Morgado_Audio-Visual_Instance_Discrimination_with_Cross-Modal_Agreement_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr25_744",
      "paper_id": "",
      "title": "Audio-Visual Instance Segmentation",
      "authors": "Ruohao Guo, Xianghua Ying, Yaru Chen, Dantong Niu, Guangyao Li, Liao Qu, Yanyu Qi, Jinxing Zhou, Bowei Xing, Wenzhen Yue, Ji Shi, Qixun Wang, Peiliang Zhang, Buwen Liang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Audio-Visual_Instance_Segmentation_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr24_1289",
      "paper_id": "",
      "title": "Audio-Visual Segmentation via Unlabeled Frame Exploitation",
      "authors": "Jinxiang Liu, Yikun Liu, Fei Zhang, Chen Ju, Ya Zhang, Yanfeng Wang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Audio-Visual_Segmentation_via_Unlabeled_Frame_Exploitation_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_2274",
      "paper_id": "",
      "title": "Audio-Visual Semantic Graph Network for Audio-Visual Event Localization",
      "authors": "Liang Liu, Shuaiyong Li, Yongqiang Zhu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Audio-Visual_Semantic_Graph_Network_for_Audio-Visual_Event_Localization_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr22_762",
      "paper_id": "",
      "title": "Audio-Visual Speech Codecs: Rethinking Audio-Visual Speech Enhancement by Re-Synthesis",
      "authors": "Karren Yang, Dejan Marković, Steven Krenn, Vasu Agrawal, Alexander Richard",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Audio-Visual_Speech_Codecs_Rethinking_Audio-Visual_Speech_Enhancement_by_Re-Synthesis_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_374",
      "paper_id": "",
      "title": "AV-RIR: Audio-Visual Room Impulse Response Estimation",
      "authors": "Anton Ratnarajah, Sreyan Ghosh, Sonal Kumar, Purva Chiniya, Dinesh Manocha",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Ratnarajah_AV-RIR_Audio-Visual_Room_Impulse_Response_Estimation_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr24_1629",
      "paper_id": "",
      "title": "AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation with Unified Audio-Visual Speech Representation",
      "authors": "Jeongsoo Choi, Se Jin Park, Minsu Kim, Yong Man Ro",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Choi_AV2AV_Direct_Audio-Visual_Speech_to_Audio-Visual_Speech_Translation_with_Unified_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr23_1899",
      "paper_id": "",
      "title": "AVFormer: Injecting Vision Into Frozen Speech Models for Zero-Shot AV-ASR",
      "authors": "Paul Hongsuck Seo, Arsha Nagrani, Cordelia Schmid",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Seo_AVFormer_Injecting_Vision_Into_Frozen_Speech_Models_for_Zero-Shot_AV-ASR_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_741",
      "paper_id": "",
      "title": "Balanced Multimodal Learning via On-the-Fly Gradient Modulation",
      "authors": "Xiaokang Peng, Yake Wei, Andong Deng, Dong Wang, Di Hu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Balanced_Multimodal_Learning_via_On-the-Fly_Gradient_Modulation_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_2137",
      "paper_id": "",
      "title": "Benchmarking Audio Visual Segmentation for Long-Untrimmed Videos",
      "authors": "Chen Liu, Peike Patrick Li, Qingtao Yu, Hongwei Sheng, Dadong Wang, Lincheng Li, Xin Yu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Liu_Benchmarking_Audio_Visual_Segmentation_for_Long-Untrimmed_Videos_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr24_937",
      "paper_id": "",
      "title": "Beyond Average: Individualized Visual Scanpath Prediction",
      "authors": "Xianyu Chen, Ming Jiang, Qi Zhao",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Beyond_Average_Individualized_Visual_Scanpath_Prediction_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_124",
      "paper_id": "",
      "title": "Beyond Image to Depth: Improving Depth Prediction Using Echoes",
      "authors": "Kranti Kumar Parida, Siddharth Srivastava, Gaurav Sharma",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Parida_Beyond_Image_to_Depth_Improving_Depth_Prediction_Using_Echoes_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr22_902",
      "paper_id": "",
      "title": "C2SLR: Consistency-Enhanced Continuous Sign Language Recognition",
      "authors": "Ronglai Zuo, Brian Mak",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zuo_C2SLR_Consistency-Enhanced_Continuous_Sign_Language_Recognition_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr21_115",
      "paper_id": "",
      "title": "Can Audio-Visual Integration Strengthen Robustness Under Multimodal Attacks?",
      "authors": "Yapeng Tian, Chenliang Xu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Can_Audio-Visual_Integration_Strengthen_Robustness_Under_Multimodal_Attacks_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr23_1519",
      "paper_id": "",
      "title": "CASP-Net: Rethinking Video Saliency Prediction From an Audio-Visual Consistency Perceptual Perspective",
      "authors": "Junwen Xiong, Ganglai Wang, Peng Zhang, Wei Huang, Yufei Zha, Guangtao Zhai",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xiong_CASP-Net_Rethinking_Video_Saliency_Prediction_From_an_Audio-Visual_Consistency_Perceptual_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr25_2183",
      "paper_id": "",
      "title": "CASP: Consistency-aware Audio-induced Saliency Prediction Model for Omnidirectional Video",
      "authors": "Zhaolin Wan, Han Qin, Zhiyang Li, Xiaopeng Fan, Wangmeng Zuo, Debin Zhao",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Wan_CASP_Consistency-aware_Audio-induced_Saliency_Prediction_Model_for_Omnidirectional_Video_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_537",
      "paper_id": "",
      "title": "CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment",
      "authors": "Edson Araujo, Andrew Rouditchenko, Yuan Gong, Saurabhchand Bhati, Samuel Thomas, Brian Kingsbury, Leonid Karlinsky, Rogerio Feris, James R. Glass, Hilde Kuehne",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Araujo_CAV-MAE_Sync_Improving_Contrastive_Audio-Visual_Mask_Autoencoders_via_Fine-Grained_Alignment_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_262",
      "paper_id": "",
      "title": "Chat2Map: Efficient Scene Mapping From Multi-Ego Conversations",
      "authors": "Sagnik Majumder, Hao Jiang, Pierre Moulon, Ethan Henderson, Paul Calamia, Kristen Grauman, Vamsi Krishna Ithapu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Majumder_Chat2Map_Efficient_Scene_Mapping_From_Multi-Ego_Conversations_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_1372",
      "paper_id": "",
      "title": "CiCo: Domain-Aware Sign Language Retrieval via Cross-Lingual Contrastive Learning",
      "authors": "Yiting Cheng, Fangyun Wei, Jianmin Bao, Dong Chen, Wenqiang Zhang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_CiCo_Domain-Aware_Sign_Language_Retrieval_via_Cross-Lingual_Contrastive_Learning_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_439",
      "paper_id": "",
      "title": "Collecting Cross-Modal Presence-Absence Evidence for Weakly-Supervised Audio-Visual Event Perception",
      "authors": "Junyu Gao, Mengyuan Chen, Changsheng Xu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Collecting_Cross-Modal_Presence-Absence_Evidence_for_Weakly-Supervised_Audio-Visual_Event_Perception_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_1538",
      "paper_id": "",
      "title": "Conditional Generation of Audio From Video via Foley Analogies",
      "authors": "Yuexi Du, Ziyang Chen, Justin Salamon, Bryan Russell, Andrew Owens",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Conditional_Generation_of_Audio_From_Video_via_Foley_Analogies_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_231",
      "paper_id": "",
      "title": "Continuous Sign Language Recognition With Correlation Network",
      "authors": "Lianyu Hu, Liqing Gao, Zekang Liu, Wei Feng",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Continuous_Sign_Language_Recognition_With_Correlation_Network_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_196",
      "paper_id": "",
      "title": "Contrastive Regression for Domain Adaptation on Gaze Estimation",
      "authors": "Yaoming Wang, Yangzhou Jiang, Jin Li, Bingbing Ni, Wenrui Dai, Chenglin Li, Hongkai Xiong, Teng Li",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Contrastive_Regression_for_Domain_Adaptation_on_Gaze_Estimation_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_982",
      "paper_id": "",
      "title": "Cooperation Does Matter: Exploring Multi-Order Bilateral Relations for Audio-Visual Segmentation",
      "authors": "Qi Yang, Xing Nie, Tong Li, Pengfei Gao, Ying Guo, Cheng Zhen, Pengfei Yan, Shiming Xiang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Cooperation_Does_Matter_Exploring_Multi-Order_Bilateral_Relations_for_Audio-Visual_Segmentation_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_739",
      "paper_id": "",
      "title": "Crab: A Unified Audio-Visual Scene Understanding Model with Explicit Cooperation",
      "authors": "Henghui Du, Guangyao Li, Chang Zhou, Chunjie Zhang, Alan Zhao, Di Hu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Du_Crab_A_Unified_Audio-Visual_Scene_Understanding_Model_with_Explicit_Cooperation_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr22_1415",
      "paper_id": "",
      "title": "Cross-Modal Background Suppression for Audio-Visual Event Localization",
      "authors": "Yan Xia, Zhou Zhao",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Cross-Modal_Background_Suppression_for_Audio-Visual_Event_Localization_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_2113",
      "paper_id": "",
      "title": "CrossMAE: Cross-Modality Masked Autoencoders for Region-Aware Audio-Visual Pre-Training",
      "authors": "Yuxin Guo, Siyang Sun, Shuailei Ma, Kecheng Zheng, Xiaoyi Bao, Shijie Ma, Wei Zou, Yun Zheng",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_CrossMAE_Cross-Modality_Masked_Autoencoders_for_Region-Aware_Audio-Visual_Pre-Training_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_882",
      "paper_id": "",
      "title": "Customized Condition Controllable Generation for Video Soundtrack",
      "authors": "Fan Qi, Kunsheng Ma, Changsheng Xu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Qi_Customized_Condition_Controllable_Generation_for_Video_Soundtrack_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_94",
      "paper_id": "",
      "title": "CVT-SLR: Contrastive Visual-Textual Transformation for Sign Language Recognition With Variational Alignment",
      "authors": "Jiangbin Zheng, Yile Wang, Cheng Tan, Siyuan Li, Ge Wang, Jun Xia, Yidong Chen, Stan Z. Li",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_CVT-SLR_Contrastive_Visual-Textual_Transformation_for_Sign_Language_Recognition_With_Variational_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr21_260",
      "paper_id": "",
      "title": "Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation",
      "authors": "Yapeng Tian, Di Hu, Chenliang Xu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Tian_Cyclic_Co-Learning_of_Sounding_Object_Visual_Grounding_and_Sound_Separation_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr24_1311",
      "paper_id": "",
      "title": "Cyclic Learning for Binaural Audio Generation and Localization",
      "authors": "Zhaojian Li, Bin Zhao, Yuan Yuan",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Cyclic_Learning_for_Binaural_Audio_Generation_and_Localization_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_60",
      "paper_id": "",
      "title": "De^2Gaze: Deformable and Decoupled Representation Learning for 3D Gaze Estimation",
      "authors": "Yunfeng Xiao, Xiaowei Bai, Baojun Chen, Hao Su, Hao He, Liang Xie, Erwei Yin",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_De2Gaze_Deformable_and_Decoupled_Representation_Learning_for_3D_Gaze_Estimation_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_1932",
      "paper_id": "",
      "title": "Dense-Localizing Audio-Visual Events in Untrimmed Videos: A Large-Scale Benchmark and Baseline",
      "authors": "Tiantian Geng, Teng Wang, Jinming Duan, Runmin Cong, Feng Zheng",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Geng_Dense-Localizing_Audio-Visual_Events_in_Untrimmed_Videos_A_Large-Scale_Benchmark_and_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr24_54",
      "paper_id": "",
      "title": "Diff-BGM: A Diffusion Model for Video Background Music Generation",
      "authors": "Sizhe Li, Yiming Qin, Minghang Zheng, Xin Jin, Yang Liu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Diff-BGM_A_Diffusion_Model_for_Video_Background_Music_Generation_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr24_439",
      "paper_id": "",
      "title": "DiffSal: Joint Audio and Video Learning for Diffusion Saliency Prediction",
      "authors": "Junwen Xiong, Peng Zhang, Tao You, Chuanyue Li, Wei Huang, Yufei Zha",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Xiong_DiffSal_Joint_Audio_and_Video_Learning_for_Diffusion_Saliency_Prediction_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_2229",
      "paper_id": "",
      "title": "Discrete to Continuous: Generating Smooth Transition Poses from Sign Language Observations",
      "authors": "Shengeng Tang, Jiayi He, Lechao Cheng, Jingjing Wu, Dan Guo, Richang Hong",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Discrete_to_Continuous_Generating_Smooth_Transition_Poses_from_Sign_Language_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_309",
      "paper_id": "",
      "title": "Distilling Cross-Temporal Contexts for Continuous Sign Language Recognition",
      "authors": "Leming Guo, Wanli Xue, Qing Guo, Bo Liu, Kaihua Zhang, Tiantian Yuan, Shengyong Chen",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Distilling_Cross-Temporal_Contexts_for_Continuous_Sign_Language_Recognition_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr24_221",
      "paper_id": "",
      "title": "DiVAS: Video and Audio Synchronization with Dynamic Frame Rates",
      "authors": "Clara Fernandez-Labrador, Mertcan Akçay, Eitan Abecassis, Joan Massich, Christopher Schroers",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Fernandez-Labrador_DiVAS_Video_and_Audio_Synchronization_with_Dynamic_Frame_Rates_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_13",
      "paper_id": "",
      "title": "Dual Attention Guided Gaze Target Detection in the Wild",
      "authors": "Yi Fang, Jiapeng Tang, Wang Shen, Wei Shen, Xiao Gu, Li Song, Guangtao Zhai",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fang_Dual_Attention_Guided_Gaze_Target_Detection_in_the_Wild_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr22_1047",
      "paper_id": "",
      "title": "Dynamic 3D Gaze From Afar: Deep Gaze Estimation From Temporal Eye-Head-Body Coordination",
      "authors": "Soma Nonaka, Shohei Nobuhara, Ko Nishino",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Nonaka_Dynamic_3D_Gaze_From_Afar_Deep_Gaze_Estimation_From_Temporal_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr25_1269",
      "paper_id": "",
      "title": "Dynamic Derivation and Elimination: Audio Visual Segmentation with Enhanced Audio Semantics",
      "authors": "Chen Liu, Liying Yang, Peike Li, Dadong Wang, Lincheng Li, Xin Yu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Dynamic_Derivation_and_Elimination_Audio_Visual_Segmentation_with_Enhanced_Audio_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_1586",
      "paper_id": "",
      "title": "Egocentric Audio-Visual Object Localization",
      "authors": "Chao Huang, Yapeng Tian, Anurag Kumar, Chenliang Xu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Egocentric_Audio-Visual_Object_Localization_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_1733",
      "paper_id": "",
      "title": "Egocentric Auditory Attention Localization in Conversations",
      "authors": "Fiona Ryan, Hao Jiang, Abhinav Shukla, James M. Rehg, Vamsi Krishna Ithapu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ryan_Egocentric_Auditory_Attention_Localization_in_Conversations_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_1995",
      "paper_id": "",
      "title": "Egocentric Deep Multi-Channel Audio-Visual Active Speaker Localization",
      "authors": "Hao Jiang, Calvin Murdock, Vamsi Krishna Ithapu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Egocentric_Deep_Multi-Channel_Audio-Visual_Active_Speaker_Localization_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr22_1886",
      "paper_id": "",
      "title": "End-to-End Human-Gaze-Target Detection With Transformers",
      "authors": "Danyang Tu, Xiongkuo Min, Huiyu Duan, Guodong Guo, Guangtao Zhai, Wei Shen",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Tu_End-to-End_Human-Gaze-Target_Detection_With_Transformers_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr25_2407",
      "paper_id": "",
      "title": "Enhancing 3D Gaze Estimation in the Wild using Weak Supervision with Gaze Following Labels",
      "authors": "Pierre Vuillecard, Jean-Marc Odobez",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Vuillecard_Enhancing_3D_Gaze_Estimation_in_the_Wild_using_Weak_Supervision_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_2594",
      "paper_id": "",
      "title": "Enhancing Dance-to-Music Generation via Negative Conditioning Latent Diffusion Model",
      "authors": "Changchang Sun, Gaowen Liu, Charles Fleming, Yan Yan",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Enhancing_Dance-to-Music_Generation_via_Negative_Conditioning_Latent_Diffusion_Model_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr24_1056",
      "paper_id": "",
      "title": "ES3: Evolving Self-Supervised Learning of Robust Audio-Visual Speech Representations",
      "authors": "Yuanhang Zhang, Shuang Yang, Shiguang Shan, Xilin Chen",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_ES3_Evolving_Self-Supervised_Learning_of_Robust_Audio-Visual_Speech_Representations_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr22_520",
      "paper_id": "",
      "title": "ESCNet: Gaze Target Detection With the Understanding of 3D Scenes",
      "authors": "Jun Bao, Buyu Liu, Jun Yu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_ESCNet_Gaze_Target_Detection_With_the_Understanding_of_3D_Scenes_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr21_236",
      "paper_id": "",
      "title": "Exploring Heterogeneous Clues for Weakly-Supervised Audio-Visual Video Parsing",
      "authors": "Yu Wu, Yi Yang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Exploring_Heterogeneous_Clues_for_Weakly-Supervised_Audio-Visual_Video_Parsing_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr25_437",
      "paper_id": "",
      "title": "Few-shot Personalized Scanpath Prediction",
      "authors": "Ruoyu Xue, Jingyi Xu, Sounak Mondal, Hieu Le, Greg Zelinsky, Minh Hoai, Dimitris Samaras",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_Few-shot_Personalized_Scanpath_Prediction_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_1917",
      "paper_id": "",
      "title": "FIFA: Fine-grained Inter-frame Attention for Driver's Video Gaze Estimation",
      "authors": "Daosong Hu, Mingyue Cui, Kai Huang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_FIFA_Fine-grained_Inter-frame_Attention_for_Drivers_Video_Gaze_Estimation_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_2178",
      "paper_id": "",
      "title": "FilmComposer: LLM-Driven Music Production for Silent Film Clips",
      "authors": "Zhifeng Xie, Qile He, Youjia Zhu, Qiwei He, Mengtian Li",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_FilmComposer_LLM-Driven_Music_Production_for_Silent_Film_Clips_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr22_1087",
      "paper_id": "",
      "title": "Finding Fallen Objects via Asynchronous Audio-Visual Integration",
      "authors": "Chuang Gan, Yi Gu, Siyuan Zhou, Jeremy Schwartz, Seth Alter, James Traer, Dan Gutfreund, Joshua B. Tenenbaum, Josh H. McDermott, Antonio Torralba",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Gan_Finding_Fallen_Objects_via_Asynchronous_Audio-Visual_Integration_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr21_468",
      "paper_id": "",
      "title": "Fingerspelling Detection in American Sign Language",
      "authors": "Bowen Shi, Diane Brentari, Greg Shakhnarovich, Karen Livescu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_Fingerspelling_Detection_in_American_Sign_Language_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr25_525",
      "paper_id": "",
      "title": "Foley-Flow: Coordinated Video-to-Audio Generation with Masked Audio-Visual Alignment and Dynamic Conditional Flows",
      "authors": "Shentong Mo, Yibing Song",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Mo_Foley-Flow_Coordinated_Video-to-Audio_Generation_with_Masked_Audio-Visual_Alignment_and_Dynamic_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr24_92",
      "paper_id": "",
      "title": "From Feature to Gaze: A Generalizable Replacement of Linear Layer for Gaze Estimation",
      "authors": "Yiwei Bao, Feng Lu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Bao_From_Feature_to_Gaze_A_Generalizable_Replacement_of_Linear_Layer_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_489",
      "paper_id": "",
      "title": "From Semantic Categories to Fixations: A Novel Weakly-Supervised Visual-Auditory Saliency Detection Approach",
      "authors": "Guotao Wang, Chenglizhao Chen, Deng-Ping Fan, Aimin Hao, Hong Qin",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_From_Semantic_Categories_to_Fixations_A_Novel_Weakly-Supervised_Visual-Auditory_Saliency_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr25_2131",
      "paper_id": "",
      "title": "FSboard: Over 3 Million Characters of ASL Fingerspelling Collected via Smartphones",
      "authors": "Manfred Georg, Garrett Tanzer, Esha Uboweja, Saad Hassan, Maximus Shengelia, Sam Sepah, Sean Forbes, Thad Starner",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Georg_FSboard_Over_3_Million_Characters_of_ASL_Fingerspelling_Collected_via_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_185",
      "paper_id": "",
      "title": "GA3CE: Unconstrained 3D Gaze Estimation with Gaze-Aware 3D Context Encoding",
      "authors": "Yuki Kawana, Shintaro Shiba, Quan Kong, Norimasa Kobori",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Kawana_GA3CE_Unconstrained_3D_Gaze_Estimation_with_Gaze-Aware_3D_Context_Encoding_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr22_913",
      "paper_id": "",
      "title": "GaTector: A Unified Framework for Gaze Object Prediction",
      "authors": "Binglu Wang, Tao Hu, Baoshan Li, Xiaojuan Chen, Zhijie Zhang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_GaTector_A_Unified_Framework_for_Gaze_Object_Prediction_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr25_2069",
      "paper_id": "",
      "title": "Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders",
      "authors": "Fiona Ryan, Ajay Bati, Sangmin Lee, Daniel Bolya, Judy Hoffman, James M. Rehg",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Ryan_Gaze-LLE_Gaze_Target_Estimation_via_Large-Scale_Learned_Encoders_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_2033",
      "paper_id": "",
      "title": "Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed Human Attention",
      "authors": "Sounak Mondal, Zhibo Yang, Seoyoung Ahn, Dimitris Samaras, Gregory Zelinsky, Minh Hoai",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Mondal_Gazeformer_Scalable_Effective_and_Fast_Prediction_of_Goal-Directed_Human_Attention_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr25_2523",
      "paper_id": "",
      "title": "GazeGene: Large-scale Synthetic Gaze Dataset with 3D Eyeball Annotations",
      "authors": "Yiwei Bao, Zhiming Wang, Feng Lu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Bao_GazeGene_Large-scale_Synthetic_Gaze_Dataset_with_3D_Eyeball_Annotations_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_2065",
      "paper_id": "",
      "title": "GazeNeRF: 3D-Aware Gaze Redirection With Neural Radiance Fields",
      "authors": "Alessandro Ruzzi, Xiangwei Shi, Xi Wang, Gengyan Li, Shalini De Mello, Hyung Jin Chang, Xucong Zhang, Otmar Hilliges",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ruzzi_GazeNeRF_3D-Aware_Gaze_Redirection_With_Neural_Radiance_Fields_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_205",
      "paper_id": "",
      "title": "GazeOnce: Real-Time Multi-Person Gaze Estimation",
      "authors": "Mingfang Zhang, Yunfei Liu, Feng Lu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_GazeOnce_Real-Time_Multi-Person_Gaze_Estimation_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr25_2189",
      "paper_id": "",
      "title": "Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging",
      "authors": "Bo Wang, Dingwei Tan, Yen-Ling Kuo, Zhaowei Sun, Jeremy M. Wolfe, Tat-Jen Cham, Mengmi Zhang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Gazing_at_Rewards_Eye_Movements_as_a_Lens_into_Human_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr22_548",
      "paper_id": "",
      "title": "Generalizing Gaze Estimation With Rotation Consistency",
      "authors": "Yiwei Bao, Yunfei Liu, Haofei Wang, Feng Lu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Generalizing_Gaze_Estimation_With_Rotation_Consistency_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr23_650",
      "paper_id": "",
      "title": "GFIE: A Dataset and Baseline for Gaze-Following From 2D to 3D in Indoor Environments",
      "authors": "Zhengxi Hu, Yuxue Yang, Xiaolin Zhai, Dingye Yang, Bohan Zhou, Jingtai Liu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_GFIE_A_Dataset_and_Baseline_for_Gaze-Following_From_2D_to_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr21_312",
      "paper_id": "",
      "title": "GLAVNet: Global-Local Audio-Visual Cues for Fine-Grained Material Recognition",
      "authors": "Fengmin Shi, Jie Guo, Haonan Zhang, Shan Yang, Xiying Wang, Yanwen Guo",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shi_GLAVNet_Global-Local_Audio-Visual_Cues_for_Fine-Grained_Material_Recognition_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr23_945",
      "paper_id": "",
      "title": "Gloss Attention for Gloss-Free Sign Language Translation",
      "authors": "Aoxiong Yin, Tianyun Zhong, Li Tang, Weike Jin, Tao Jin, Zhou Zhao",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yin_Gloss_Attention_for_Gloss-Free_Sign_Language_Translation_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_1129",
      "paper_id": "",
      "title": "Ham2Pose: Animating Sign Language Notation Into Pose Sequences",
      "authors": "Rotem Shalev Arkushin, Amit Moryossef, Ohad Fried",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Arkushin_Ham2Pose_Animating_Sign_Language_Notation_Into_Pose_Sequences_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr25_218",
      "paper_id": "",
      "title": "HarmonySet: A Comprehensive Dataset for Understanding Video-Music Semantic Alignment and Temporal Synchronization",
      "authors": "Zitang Zhou, Ke Mei, Yu Lu, Tianyi Wang, Fengyun Rao",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_HarmonySet_A_Comprehensive_Dataset_for_Understanding_Video-Music_Semantic_Alignment_and_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr24_984",
      "paper_id": "",
      "title": "Hearing Anything Anywhere",
      "authors": "Mason Long Wang, Ryosuke Sawata, Samuel Clarke, Ruohan Gao, Shangzhe Wu, Jiajun Wu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Hearing_Anything_Anywhere_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_2728",
      "paper_id": "",
      "title": "Hearing Anywhere in Any Environment",
      "authors": "Xiulong Liu, Anurag Kumar, Paul Calamia, Sebastia V. Amengual, Calvin Murdock, Ishwarya Ananthabhotla, Philip Robinson, Eli Shlizerman, Vamsi Krishna Ithapu, Ruohan Gao",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hearing_Anywhere_in_Any_Environment_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_645",
      "paper_id": "",
      "title": "Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes",
      "authors": "Yiming Dou, Wonseok Oh, Yuqing Luo, Antonio Loquercio, Andrew Owens",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Dou_Hearing_Hands_Generating_Sounds_from_Physical_Interactions_in_3D_Scenes_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr21_1473",
      "paper_id": "",
      "title": "How2Sign: A Large-Scale Multimodal Dataset for Continuous American Sign Language",
      "authors": "Amanda Duarte, Shruti Palaskar, Lucas Ventura, Deepti Ghadiyaram, Kenneth DeHaan, Florian Metze, Jordi Torres, Xavier Giro-i-Nieto",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Duarte_How2Sign_A_Large-Scale_Multimodal_Dataset_for_Continuous_American_Sign_Language_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr21_153",
      "paper_id": "",
      "title": "Improving Sign Language Translation With Monolingual Data by Sign Back-Translation",
      "authors": "Hao Zhou, Wengang Zhou, Weizhen Qi, Junfu Pu, Houqiang Li",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Improving_Sign_Language_Translation_With_Monolingual_Data_by_Sign_Back-Translation_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr25_2378",
      "paper_id": "",
      "title": "Improving Sound Source Localization with Joint Slot Attention on Image and Audio",
      "authors": "Inho Kim, Youngkil Song, Jicheol Park, Won Hwa Kim, Suha Kwak",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Improving_Sound_Source_Localization_with_Joint_Slot_Attention_on_Image_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_779",
      "paper_id": "",
      "title": "iQuery: Instruments As Queries for Audio-Visual Sound Separation",
      "authors": "Jiaben Chen, Renrui Zhang, Dongze Lian, Jiaqi Yang, Ziyao Zeng, Jianbo Shi",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_iQuery_Instruments_As_Queries_for_Audio-Visual_Sound_Separation_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_125",
      "paper_id": "",
      "title": "It's Time for Artistic Correspondence in Music and Video",
      "authors": "Dídac Surís, Carl Vondrick, Bryan Russell, Justin Salamon",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Suris_Its_Time_for_Artistic_Correspondence_in_Music_and_Video_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr23_93",
      "paper_id": "",
      "title": "Language-Guided Audio-Visual Source Separation via Trimodal Consistency",
      "authors": "Reuben Tan, Arijit Ray, Andrea Burns, Bryan A. Plummer, Justin Salamon, Oriol Nieto, Bryan Russell, Kate Saenko",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_Language-Guided_Audio-Visual_Source_Separation_via_Trimodal_Consistency_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_2010",
      "paper_id": "",
      "title": "Language-Guided Music Recommendation for Video via Prompt Analogies",
      "authors": "Daniel McKee, Justin Salamon, Josef Sivic, Bryan Russell",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/McKee_Language-Guided_Music_Recommendation_for_Video_via_Prompt_Analogies_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_1225",
      "paper_id": "",
      "title": "Learning Audio-Visual Source Localization via False Negative Aware Contrastive Learning",
      "authors": "Weixuan Sun, Jiayi Zhang, Jianyuan Wang, Zheyuan Liu, Yiran Zhong, Tianpeng Feng, Yandong Guo, Yanhao Zhang, Nick Barnes",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Learning_Audio-Visual_Source_Localization_via_False_Negative_Aware_Contrastive_Learning_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr24_2544",
      "paper_id": "",
      "title": "Learning from Observer Gaze: Zero-Shot Attention Prediction Oriented by Human-Object Interaction Recognition",
      "authors": "Yuchen Zhou, Linkai Liu, Chao Gou",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Zhou_Learning_from_Observer_Gaze_Zero-Shot_Attention_Prediction_Oriented_by_Human-Object_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_717",
      "paper_id": "",
      "title": "Learning From the Master: Distilling Cross-Modal Advanced Knowledge for Lip Reading",
      "authors": "Sucheng Ren, Yong Du, Jianming Lv, Guoqiang Han, Shengfeng He",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_Learning_From_the_Master_Distilling_Cross-Modal_Advanced_Knowledge_for_Lip_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr23_1380",
      "paper_id": "",
      "title": "Learning From Unique Perspectives: User-Aware Saliency Modeling",
      "authors": "Shi Chen, Nachiappan Valliappan, Shaolei Shen, Xinyu Ye, Kai Kohlhoff, Junfeng He",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Learning_From_Unique_Perspectives_User-Aware_Saliency_Modeling_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr24_1405",
      "paper_id": "",
      "title": "Learning Spatial Features from Audio-Visual Correspondence in Egocentric Videos",
      "authors": "Sagnik Majumder, Ziad Al-Halah, Kristen Grauman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Majumder_Learning_Spatial_Features_from_Audio-Visual_Correspondence_in_Egocentric_Videos_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr22_2000",
      "paper_id": "",
      "title": "Learning To Answer Questions in Dynamic Audio-Visual Scenarios",
      "authors": "Guangyao Li, Yake Wei, Yapeng Tian, Chenliang Xu, Ji-Rong Wen, Di Hu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr25_2080",
      "paper_id": "",
      "title": "Learning to Highlight Audio by Watching Movies",
      "authors": "Chao Huang, Ruohan Gao, J. M. F. Tsang, Jan Kurcius, Cagdas Bilen, Chenliang Xu, Anurag Kumar, Sanjeel Parekh",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Learning_to_Highlight_Audio_by_Watching_Movies_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr24_1075",
      "paper_id": "",
      "title": "Learning to Visually Localize Sound Sources from Mixtures without Prior Source Knowledge",
      "authors": "Dongjin Kim, Sung Jin Um, Sangmin Lee, Jung Uk Kim",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Kim_Learning_to_Visually_Localize_Sound_Sources_from_Mixtures_without_Prior_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_470",
      "paper_id": "",
      "title": "Learning Triadic Belief Dynamics in Nonverbal Communication From Videos",
      "authors": "Lifeng Fan, Shuwen Qiu, Zilong Zheng, Tao Gao, Song-Chun Zhu, Yixin Zhu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Learning_Triadic_Belief_Dynamics_in_Nonverbal_Communication_From_Videos_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr24_126",
      "paper_id": "",
      "title": "LLMs are Good Sign Language Translators",
      "authors": "Jia Gong, Lin Geng Foo, Yixuan He, Hossein Rahmani, Jun Liu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Gong_LLMs_are_Good_Sign_Language_Translators_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_129",
      "paper_id": "",
      "title": "Localizing Visual Sounds the Hard Way",
      "authors": "Honglie Chen, Weidi Xie, Triantafyllos Afouras, Arsha Nagrani, Andrea Vedaldi, Andrew Zisserman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Localizing_Visual_Sounds_the_Hard_Way_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr24_1047",
      "paper_id": "",
      "title": "LoCoNet: Long-Short Context Network for Active Speaker Detection",
      "authors": "Xizi Wang, Feng Cheng, Gedas Bertasius",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_LoCoNet_Long-Short_Context_Network_for_Active_Speaker_Detection_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_1628",
      "paper_id": "",
      "title": "Looking Into Your Speech: Learning Cross-Modal Affinity for Audio-Visual Speech Separation",
      "authors": "Jiyoung Lee, Soo-Whan Chung, Sunok Kim, Hong-Goo Kang, Kwanghoon Sohn",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Looking_Into_Your_Speech_Learning_Cross-Modal_Affinity_for_Audio-Visual_Speech_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr24_55",
      "paper_id": "",
      "title": "Looking Similar Sounding Different: Leveraging Counterfactual Cross-Modal Pairs for Audiovisual Representation Learning",
      "authors": "Nikhil Singh, Chih-Wei Wu, Iroro Orife, Mahdi Kalayeh",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Singh_Looking_Similar_Sounding_Different_Leveraging_Counterfactual_Cross-Modal_Pairs_for_Audiovisual_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_475",
      "paper_id": "",
      "title": "Lost in Translation, Found in Context: Sign Language Translation with Contextual Cues",
      "authors": "Youngjoon Jang, Haran Raajesh, Liliane Momeni, Gül Varol, Andrew Zisserman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Lost_in_Translation_Found_in_Context_Sign_Language_Translation_with_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr24_1115",
      "paper_id": "",
      "title": "MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models",
      "authors": "Sanjoy Chowdhury, Sayan Nag, K J Joseph, Balaji Vasan Srinivasan, Dinesh Manocha",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chowdhury_MeLFusion_Synthesizing_Music_from_Image_and_Language_Cues_using_Diffusion_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr22_1051",
      "paper_id": "",
      "title": "Mix and Localize: Localizing Sound Sources in Mixtures",
      "authors": "Xixi Hu, Ziyang Chen, Andrew Owens",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Mix_and_Localize_Localizing_Sound_Sources_in_Mixtures_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr22_1098",
      "paper_id": "",
      "title": "MLSLT: Towards Multilingual Sign Language Translation",
      "authors": "Aoxiong Yin, Zhou Zhao, Weike Jin, Meng Zhang, Xingshan Zeng, Xiaofei He",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_MLSLT_Towards_Multilingual_Sign_Language_Translation_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr23_662",
      "paper_id": "",
      "title": "MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation",
      "authors": "Ludan Ruan, Yiyang Ma, Huan Yang, Huiguo He, Bei Liu, Jianlong Fu, Nicholas Jing Yuan, Qin Jin, Baining Guo",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ruan_MM-Diffusion_Learning_Multi-Modal_Diffusion_Models_for_Joint_Audio_and_Video_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr25_2701",
      "paper_id": "",
      "title": "MMAudio: Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis",
      "authors": "Ho Kei Cheng, Masato Ishii, Akio Hayakawa, Takashi Shibuya, Alexander Schwing, Yuki Mitsufuji",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_MMAudio_Taming_Multimodal_Joint_Training_for_High-Quality_Video-to-Audio_Synthesis_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr24_1320",
      "paper_id": "",
      "title": "Modeling Multimodal Social Interactions: New Challenges and Baselines with Densely Aligned Representations",
      "authors": "Sangmin Lee, Bolin Lai, Fiona Ryan, Bikram Boote, James M. Rehg",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Lee_Modeling_Multimodal_Social_Interactions_New_Challenges_and_Baselines_with_Densely_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_899",
      "paper_id": "",
      "title": "Multi-Perspective LSTM for Joint Visual Representation Learning",
      "authors": "Alireza Sepas-Moghaddam, Fernando Pereira, Paulo Lobato Correia, Ali Etemad",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sepas-Moghaddam_Multi-Perspective_LSTM_for_Joint_Visual_Representation_Learning_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr24_835",
      "paper_id": "",
      "title": "MuseChat: A Conversational Music Recommendation System for Videos",
      "authors": "Zhikang Dong, Xiulong Liu, Bin Chen, Pawel Polak, Peng Zhang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Dong_MuseChat_A_Conversational_Music_Recommendation_System_for_Videos_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr23_640",
      "paper_id": "",
      "title": "Natural Language-Assisted Sign Language Recognition",
      "authors": "Ronglai Zuo, Fangyun Wei, Brian Mak",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zuo_Natural_Language-Assisted_Sign_Language_Recognition_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr24_1139",
      "paper_id": "",
      "title": "Neural Sign Actors: A Diffusion Model for 3D Sign Language Production from Text",
      "authors": "Vasileios Baltatzis, Rolandos Alexandros Potamias, Evangelos Ververas, Guanxiong Sun, Jiankang Deng, Stefanos Zafeiriou",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Baltatzis_Neural_Sign_Actors_A_Diffusion_Model_for_3D_Sign_Language_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr23_665",
      "paper_id": "",
      "title": "Novel-View Acoustic Synthesis",
      "authors": "Changan Chen, Alexander Richard, Roman Shapovalov, Vamsi Krishna Ithapu, Natalia Neverova, Kristen Grauman, Andrea Vedaldi",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Novel-View_Acoustic_Synthesis_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr25_1740",
      "paper_id": "",
      "title": "Object-aware Sound Source Localization via Audio-Visual Scene Understanding",
      "authors": "Sung Jin Um, Dongjin Kim, Sangmin Lee, Jung Uk Kim",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Um_Object-aware_Sound_Source_Localization_via_Audio-Visual_Scene_Understanding_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_711",
      "paper_id": "",
      "title": "Physics-Driven Diffusion Models for Impact Sound Synthesis From Videos",
      "authors": "Kun Su, Kaizhi Qian, Eli Shlizerman, Antonio Torralba, Chuang Gan",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Su_Physics-Driven_Diffusion_Models_for_Impact_Sound_Synthesis_From_Videos_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr21_347",
      "paper_id": "",
      "title": "Positive Sample Propagation Along the Audio-Visual Event Line",
      "authors": "Jinxing Zhou, Liang Zheng, Yiran Zhong, Shijie Hao, Meng Wang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Positive_Sample_Propagation_Along_the_Audio-Visual_Event_Line_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr21_666",
      "paper_id": "",
      "title": "Predicting Human Scanpaths in Visual Question Answering",
      "authors": "Xianyu Chen, Ming Jiang, Qi Zhao",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Predicting_Human_Scanpaths_in_Visual_Question_Answering_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr22_561",
      "paper_id": "",
      "title": "PyMiceTracking: An Open-Source Toolbox for Real-Time Behavioral Neuroscience Experiments",
      "authors": "Richardson Menezes, Aron de Miranda, Helton Maia",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Menezes_PyMiceTracking_An_Open-Source_Toolbox_for_Real-Time_Behavioral_Neuroscience_Experiments_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_1529",
      "paper_id": "",
      "title": "QDFormer: Towards Robust Audiovisual Segmentation in Complex Environments with Quantization-based Semantic Decomposition",
      "authors": "Xiang Li, Jinglu Wang, Xiaohao Xu, Xiulian Peng, Rita Singh, Yan Lu, Bhiksha Raj",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Li_QDFormer_Towards_Robust_Audiovisual_Segmentation_in_Complex_Environments_with_Quantization-based_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_1430",
      "paper_id": "",
      "title": "Read and Attend: Temporal Localisation in Sign Language Videos",
      "authors": "Gul Varol, Liliane Momeni, Samuel Albanie, Triantafyllos Afouras, Andrew Zisserman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Varol_Read_and_Attend_Temporal_Localisation_in_Sign_Language_Videos_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr22_1386",
      "paper_id": "",
      "title": "Reading To Listen at the Cocktail Party: Multi-Modal Speech Separation",
      "authors": "Akam Rahimi, Triantafyllos Afouras, Andrew Zisserman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Rahimi_Reading_To_Listen_at_the_Cocktail_Party_Multi-Modal_Speech_Separation_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_2194",
      "paper_id": "",
      "title": "Real Acoustic Fields: An Audio-Visual Room Acoustics Dataset and Benchmark",
      "authors": "Ziyang Chen, Israel D. Gebru, Christian Richardt, Anurag Kumar, William Laney, Andrew Owens, Alexander Richard",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Real_Acoustic_Fields_An_Audio-Visual_Room_Acoustics_Dataset_and_Benchmark_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr23_476",
      "paper_id": "",
      "title": "RealImpact: A Dataset of Impact Sound Fields for Real Objects",
      "authors": "Samuel Clarke, Ruohan Gao, Mason Wang, Mark Rau, Julia Xu, Jui-Hsien Wang, Doug L. James, Jiajun Wu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Clarke_RealImpact_A_Dataset_of_Impact_Sound_Fields_for_Real_Objects_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_446",
      "paper_id": "",
      "title": "Reconstructing Signing Avatars From Video Using Linguistic Priors",
      "authors": "Maria-Paola Forte, Peter Kulits, Chun-Hao P. Huang, Vasileios Choutas, Dimitrios Tzionas, Katherine J. Kuchenbecker, Michael J. Black",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Forte_Reconstructing_Signing_Avatars_From_Video_Using_Linguistic_Priors_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_2171",
      "paper_id": "",
      "title": "ReDirTrans: Latent-to-Latent Translation for Gaze and Head Redirection",
      "authors": "Shiwei Jin, Zhen Wang, Lei Wang, Ning Bi, Truong Nguyen",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_ReDirTrans_Latent-to-Latent_Translation_for_Gaze_and_Head_Redirection_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr23_1683",
      "paper_id": "",
      "title": "ReVISE: Self-Supervised Speech Resynthesis With Visual Input for Universal and Generalized Speech Regeneration",
      "authors": "Wei-Ning Hsu, Tal Remez, Bowen Shi, Jacob Donley, Yossi Adi",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hsu_ReVISE_Self-Supervised_Speech_Resynthesis_With_Visual_Input_for_Universal_and_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr25_1047",
      "paper_id": "",
      "title": "Revisiting Audio-Visual Segmentation with Vision-Centric Transformer",
      "authors": "Shaofei Huang, Rui Ling, Tianrui Hui, Hongyu Li, Xu Zhou, Shifeng Zhang, Si Liu, Richang Hong, Meng Wang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Revisiting_Audio-Visual_Segmentation_with_Vision-Centric_Transformer_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr21_1064",
      "paper_id": "",
      "title": "Robust Audio-Visual Instance Discrimination",
      "authors": "Pedro Morgado, Ishan Misra, Nuno Vasconcelos",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Morgado_Robust_Audio-Visual_Instance_Discrimination_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr25_2027",
      "paper_id": "",
      "title": "Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment",
      "authors": "Chen Liu, Peike Li, Liying Yang, Dadong Wang, Lincheng Li, Xin Yu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Robust_Audio-Visual_Segmentation_via_Audio-Guided_Visual_Convergent_Alignment_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_61",
      "paper_id": "",
      "title": "ScanDMM: A Deep Markov Model of Scanpath Prediction for 360deg Images",
      "authors": "Xiangjie Sui, Yuming Fang, Hanwei Zhu, Shiqi Wang, Zhou Wang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sui_ScanDMM_A_Deep_Markov_Model_of_Scanpath_Prediction_for_360deg_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr24_270",
      "paper_id": "",
      "title": "Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners",
      "authors": "Yazhou Xing, Yingqing He, Zeyue Tian, Xintao Wang, Qifeng Chen",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Xing_Seeing_and_Hearing_Open-domain_Visual-Audio_Generation_with_Diffusion_Latent_Aligners_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_735",
      "paper_id": "",
      "title": "Seeing Speech and Sound: Distinguishing and Locating Audio Sources in Visual Scenes",
      "authors": "Hyeonggon Ryu, Seongyu Kim, Joon Son Chung, Arda Senocak",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Ryu_Seeing_Speech_and_Sound_Distinguishing_and_Locating_Audio_Sources_in_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr22_1620",
      "paper_id": "",
      "title": "Self-Supervised Object Detection From Audio-Visual Correspondence",
      "authors": "Triantafyllos Afouras, Yuki M. Asano, Francois Fagan, Andrea Vedaldi, Florian Metze",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Afouras_Self-Supervised_Object_Detection_From_Audio-Visual_Correspondence_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr21_602",
      "paper_id": "",
      "title": "Semantic Audio-Visual Navigation",
      "authors": "Changan Chen, Ziad Al-Halah, Kristen Grauman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Semantic_Audio-Visual_Navigation_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr24_1761",
      "paper_id": "",
      "title": "Separating the \"Chirp\" from the \"Chat\": Self-supervised Visual Grounding of Sound and Language",
      "authors": "Mark Hamilton, Andrew Zisserman, John R. Hershey, William T. Freeman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Hamilton_Separating_the_Chirp_from_the_Chat_Self-supervised_Visual_Grounding_of_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr24_60",
      "paper_id": "",
      "title": "Sharingan: A Transformer Architecture for Multi-Person Gaze Following",
      "authors": "Samy Tafasca, Anshul Gupta, Jean-Marc Odobez",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Tafasca_Sharingan_A_Transformer_Architecture_for_Multi-Person_Gaze_Following_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr22_1681",
      "paper_id": "",
      "title": "Sign Language Video Retrieval With Free-Form Textual Queries",
      "authors": "Amanda Duarte, Samuel Albanie, Xavier Giró-i-Nieto, Gül Varol",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Duarte_Sign_Language_Video_Retrieval_With_Free-Form_Textual_Queries_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_1791",
      "paper_id": "",
      "title": "SignGraph: A Sign Sequence is Worth Graphs of Nodes",
      "authors": "Shiwei Gan, Yafeng Yin, Zhiwei Jiang, Hongkai Wen, Lei Xie, Sanglu Lu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Gan_SignGraph_A_Sign_Sequence_is_Worth_Graphs_of_Nodes_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr22_677",
      "paper_id": "",
      "title": "Signing at Scale: Learning to Co-Articulate Signs for Large-Scale Photo-Realistic Sign Language Production",
      "authors": "Ben Saunders, Necati Cihan Camgoz, Richard Bowden",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Saunders_Signing_at_Scale_Learning_to_Co-Articulate_Signs_for_Large-Scale_Photo-Realistic_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_1615",
      "paper_id": "",
      "title": "SonicVisionLM: Playing Sound with Vision Language Models",
      "authors": "Zhifeng Xie, Shengye Yu, Qile He, Mengtian Li",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Xie_SonicVisionLM_Playing_Sound_with_Vision_Language_Models_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr22_1326",
      "paper_id": "",
      "title": "Sound and Visual Representation Learning With Multiple Pretraining Tasks",
      "authors": "Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Vasudevan_Sound_and_Visual_Representation_Learning_With_Multiple_Pretraining_Tasks_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr23_1191",
      "paper_id": "",
      "title": "Sound to Visual Scene Generation by Audio-to-Visual Latent Alignment",
      "authors": "Kim Sung-Bin, Arda Senocak, Hyunwoo Ha, Andrew Owens, Tae-Hyun Oh",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Sung-Bin_Sound_to_Visual_Scene_Generation_by_Audio-to-Visual_Latent_Alignment_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_1882",
      "paper_id": "",
      "title": "Sound-Guided Semantic Image Manipulation",
      "authors": "Seung Hyun Lee, Wonseok Roh, Wonmin Byeon, Sang Ho Yoon, Chanyoung Kim, Jinkyu Kim, Sangpil Kim",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Sound-Guided_Semantic_Image_Manipulation_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_1484",
      "paper_id": "",
      "title": "SoundingActions: Learning How Actions Sound from Narrated Egocentric Videos",
      "authors": "Changan Chen, Kumar Ashutosh, Rohit Girdhar, David Harwath, Kristen Grauman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_SoundingActions_Learning_How_Actions_Sound_from_Narrated_Egocentric_Videos_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_1546",
      "paper_id": "",
      "title": "SoundVista: Novel-View Ambient Sound Synthesis via Visual-Acoustic Binding",
      "authors": "Mingfei Chen, Israel D. Gebru, Ishwarya Ananthabhotla, Christian Richardt, Dejan Markovic, Jake Sandakly, Steven Krenn, Todd Keebler, Eli Shlizerman, Alexander Richard",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SoundVista_Novel-View_Ambient_Sound_Synthesis_via_Visual-Acoustic_Binding_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_1251",
      "paper_id": "",
      "title": "Source-Free Adaptive Gaze Estimation by Uncertainty Reduction",
      "authors": "Xin Cai, Jiabei Zeng, Shiguang Shan, Xilin Chen",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cai_Source-Free_Adaptive_Gaze_Estimation_by_Uncertainty_Reduction_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_92",
      "paper_id": "",
      "title": "Sub-Word Level Lip Reading With Visual Attention",
      "authors": "K R Prajwal, Triantafyllos Afouras, Andrew Zisserman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Prajwal_Sub-Word_Level_Lip_Reading_With_Visual_Attention_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr25_770",
      "paper_id": "",
      "title": "Supervising Sound Localization by In-the-wild Egomotion",
      "authors": "Anna Min, Ziyang Chen, Hang Zhao, Andrew Owens",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Min_Supervising_Sound_Localization_by_In-the-wild_Egomotion_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_478",
      "paper_id": "",
      "title": "Synchronized Video-to-Audio Generation via Mel Quantization-Continuum Decomposition",
      "authors": "Juncheng Wang, Chao Xu, Cheng Yu, Lei Shang, Zhe Hu, Shujun Wang, Liefeng Bo",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Synchronized_Video-to-Audio_Generation_via_Mel_Quantization-Continuum_Decomposition_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_166",
      "paper_id": "",
      "title": "SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision",
      "authors": "Xubo Liu, Egor Lakomkin, Konstantinos Vougioukas, Pingchuan Ma, Honglie Chen, Ruiming Xie, Morrie Doulaty, Niko Moritz, Jachym Kolar, Stavros Petridis, Maja Pantic, Christian Fuegen",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_SynthVSR_Scaling_Up_Visual_Speech_Recognition_With_Synthetic_Supervision_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr24_498",
      "paper_id": "",
      "title": "T-VSL: Text-Guided Visual Sound Source Localization in Mixtures",
      "authors": "Tanvir Mahmud, Yapeng Tian, Diana Marculescu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Mahmud_T-VSL_Text-Guided_Visual_Sound_Source_Localization_in_Mixtures_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr23_507",
      "paper_id": "",
      "title": "TempSAL - Uncovering Temporal Information for Deep Saliency Prediction",
      "authors": "Bahar Aydemir, Ludo Hoffstetter, Tong Zhang, Mathieu Salzmann, Sabine Süsstrunk",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Aydemir_TempSAL_-_Uncovering_Temporal_Information_for_Deep_Saliency_Prediction_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr24_765",
      "paper_id": "",
      "title": "The Audio-Visual Conversational Graph: From an Egocentric-Exocentric Perspective",
      "authors": "Wenqi Jia, Miao Liu, Hao Jiang, Ishwarya Ananthabhotla, James M. Rehg, Vamsi Krishna Ithapu, Ruohan Gao",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Jia_The_Audio-Visual_Conversational_Graph_From_an_Egocentric-Exocentric_Perspective_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_1096",
      "paper_id": "",
      "title": "There Is More Than Meets the Eye: Self-Supervised Multi-Object Detection and Tracking With Sound by Distilling Multimodal Knowledge",
      "authors": "Francisco Rivera Valverde, Juana Valeria Hurtado, Abhinav Valada",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Valverde_There_Is_More_Than_Meets_the_Eye_Self-Supervised_Multi-Object_Detection_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr25_2620",
      "paper_id": "",
      "title": "Towards Open-Vocabulary Audio-Visual Event Localization",
      "authors": "Jinxing Zhou, Dan Guo, Ruohao Guo, Yuxin Mao, Jingjing Hu, Yiran Zhong, Xiaojun Chang, Meng Wang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Towards_Open-Vocabulary_Audio-Visual_Event_Localization_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr24_1648",
      "paper_id": "",
      "title": "Unifying Top-down and Bottom-up Scanpath Prediction Using Transformers",
      "authors": "Zhibo Yang, Sounak Mondal, Seoyoung Ahn, Ruoyu Xue, Gregory Zelinsky, Minh Hoai, Dimitris Samaras",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Unifying_Top-down_and_Bottom-up_Scanpath_Prediction_Using_Transformers_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr24_155",
      "paper_id": "",
      "title": "Unraveling Instance Associations: A Closer Look for Audio-Visual Segmentation",
      "authors": "Yuanhong Chen, Yuyuan Liu, Hu Wang, Fengbei Liu, Chong Wang, Helen Frazer, Gustavo Carneiro",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_Unraveling_Instance_Associations_A_Closer_Look_for_Audio-Visual_Segmentation_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr24_2111",
      "paper_id": "",
      "title": "Unsupervised Gaze Representation Learning from Multi-view Face Images",
      "authors": "Yiwei Bao, Feng Lu",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Bao_Unsupervised_Gaze_Representation_Learning_from_Multi-view_Face_Images_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr24_657",
      "paper_id": "",
      "title": "Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling",
      "authors": "Shentong Mo, Pedro Morgado",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Mo_Unveiling_the_Power_of_Audio-Visual_Early_Fusion_Transformers_with_Dense_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr25_1522",
      "paper_id": "",
      "title": "UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing",
      "authors": "Yung-Hsuan Lai, Janek Ebbers, Yu-Chiang Frank Wang, François Germain, Michael Jeffrey Jones, Moitreya Chatterjee",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_UWAV_Uncertainty-weighted_Weakly-supervised_Audio-Visual_Video_Parsing_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_1346",
      "paper_id": "",
      "title": "Video-Guided Foley Sound Generation with Multimodal Controls",
      "authors": "Ziyang Chen, Prem Seetharaman, Bryan Russell, Oriol Nieto, David Bourgin, Andrew Owens, Justin Salamon",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Video-Guided_Foley_Sound_Generation_with_Multimodal_Controls_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_2115",
      "paper_id": "",
      "title": "VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling",
      "authors": "Zeyue Tian, Zhaoyang Liu, Ruibin Yuan, Jiahao Pan, Qifeng Liu, Xu Tan, Qifeng Chen, Wei Xue, Yike Guo",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_VidMuse_A_Simple_Video-to-Music_Generation_Framework_with_Long-Short-Term_Modeling_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr25_2416",
      "paper_id": "",
      "title": "VinTAGe: Joint Video and Text Conditioning for Holistic Audio Generation",
      "authors": "Saksham Singh Kushwaha, Yapeng Tian",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Kushwaha_VinTAGe_Joint_Video_and_Text_Conditioning_for_Holistic_Audio_Generation_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr22_1604",
      "paper_id": "",
      "title": "Visual Acoustic Matching",
      "authors": "Changan Chen, Ruohan Gao, Paul Calamia, Kristen Grauman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Visual_Acoustic_Matching_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr21_12",
      "paper_id": "",
      "title": "Visually Informed Binaural Audio Generation without Binaural Audios",
      "authors": "Xudong Xu, Hang Zhou, Ziwei Liu, Bo Dai, Xiaogang Wang, Dahua Lin",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Visually_Informed_Binaural_Audio_Generation_without_Binaural_Audios_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr21_1178",
      "paper_id": "",
      "title": "VisualVoice: Audio-Visual Speech Separation With Cross-Modal Consistency",
      "authors": "Ruohan Gao, Kristen Grauman",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_VisualVoice_Audio-Visual_Speech_Separation_With_Cross-Modal_Consistency_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr25_2784",
      "paper_id": "",
      "title": "VSNet: Focusing on the Linguistic Characteristics of Sign Language",
      "authors": "Yuhao Li, Xinyue Chen, Hongkai Li, Xiaorong Pu, Peng Jin, Yazhou Ren",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2025/papers/Li_VSNet_Focusing_on_the_Linguistic_Characteristics_of_Sign_Language_CVPR_2025_paper.pdf",
      "venue": "cvpr25"
    },
    {
      "id": "cvpr23_830",
      "paper_id": "",
      "title": "Watch or Listen: Robust Audio-Visual Speech Recognition With Visual Corruption Modeling and Reliability Scoring",
      "authors": "Joanna Hong, Minsu Kim, Jeongsoo Choi, Yong Man Ro",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Hong_Watch_or_Listen_Robust_Audio-Visual_Speech_Recognition_With_Visual_Corruption_CVPR_2023_paper.pdf",
      "venue": "cvpr23"
    },
    {
      "id": "cvpr22_1440",
      "paper_id": "",
      "title": "Weakly Paired Associative Learning for Sound and Image Representations via Bimodal Associative Memory",
      "authors": "Sangmin Lee, Hyung-Il Kim, Yong Man Ro",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Paired_Associative_Learning_for_Sound_and_Image_Representations_via_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    },
    {
      "id": "cvpr24_663",
      "paper_id": "",
      "title": "Weakly-Supervised Audio-Visual Video Parsing with Prototype-based Pseudo-Labeling",
      "authors": "Kranthi Kumar Rachavarapu, Kalyan Ramakrishnan, Rajagopalan A. N.",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Rachavarapu_Weakly-Supervised_Audio-Visual_Video_Parsing_with_Prototype-based_Pseudo-Labeling_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr21_1246",
      "paper_id": "",
      "title": "Weakly-Supervised Physically Unconstrained Gaze Estimation",
      "authors": "Rakshit Kothari, Shalini De Mello, Umar Iqbal, Wonmin Byeon, Seonwook Park, Jan Kautz",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Kothari_Weakly-Supervised_Physically_Unconstrained_Gaze_Estimation_CVPR_2021_paper.pdf",
      "venue": "cvpr21"
    },
    {
      "id": "cvpr24_872",
      "paper_id": "",
      "title": "What Do You See in Vehicle? Comprehensive Vision Solution for In-Vehicle Gaze Estimation",
      "authors": "Yihua Cheng, Yaning Zhu, Zongji Wang, Hongquan Hao, Yongwei Liu, Shiqing Cheng, Xi Wang, Hyung Jin Chang",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2024/papers/Cheng_What_Do_You_See_in_Vehicle_Comprehensive_Vision_Solution_for_CVPR_2024_paper.pdf",
      "venue": "cvpr24"
    },
    {
      "id": "cvpr22_1202",
      "paper_id": "",
      "title": "Wnet: Audio-Guided Video Object Segmentation via Wavelet-Based Cross-Modal Denoising Networks",
      "authors": "Wenwen Pan, Haonan Shi, Zhou Zhao, Jieming Zhu, Xiuqiang He, Zhigeng Pan, Lianli Gao, Jun Yu, Fei Wu, Qi Tian",
      "paper_url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Wnet_Audio-Guided_Video_Object_Segmentation_via_Wavelet-Based_Cross-Modal_Denoising_Networks_CVPR_2022_paper.pdf",
      "venue": "cvpr22"
    }
  ]
}